{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import impute\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read file and make initial replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train = pd.read_csv('./data/application_train.csv')\n",
    "application_test = pd.read_csv('./data/application_test.csv')\n",
    "\n",
    "application_train.replace('XNA', np.NaN, inplace = True)\n",
    "application_train['age_yrs'] = np.negative(application_train['DAYS_BIRTH'])/365\n",
    "application_train['yrs_emp'] = np.negative(application_train['DAYS_EMPLOYED'])/365\n",
    "application_train['yrs_registration'] = np.negative(application_train['DAYS_REGISTRATION'])/365\n",
    "application_train['yrs_id_publish'] = np.negative(application_train['DAYS_ID_PUBLISH'])/365\n",
    "application_train['yrs_last_phone_change'] = np.negative(application_train['DAYS_LAST_PHONE_CHANGE'])/365\n",
    "application_train = application_train.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'DAYS_LAST_PHONE_CHANGE'], axis = 1)\n",
    "\n",
    "application_test.replace('XNA', np.NaN, inplace = True)\n",
    "application_test['age_yrs'] = np.negative(application_test['DAYS_BIRTH'])/365\n",
    "application_test['yrs_emp'] = np.negative(application_test['DAYS_EMPLOYED'])/365\n",
    "application_test['yrs_registration'] = np.negative(application_test['DAYS_REGISTRATION'])/365\n",
    "application_test['yrs_id_publish'] = np.negative(application_test['DAYS_ID_PUBLISH'])/365\n",
    "application_test['yrs_last_phone_change'] = np.negative(application_test['DAYS_LAST_PHONE_CHANGE'])/365\n",
    "application_test = application_test.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'DAYS_LAST_PHONE_CHANGE'], axis = 1)\n",
    "\n",
    "# imputing self-proclaimed-income anomalies\n",
    "inc_anomalies = application_train[(application_train.AMT_INCOME_TOTAL - np.mean(application_train.AMT_INCOME_TOTAL))/np.std(application_train.AMT_INCOME_TOTAL) > 3]\n",
    "application_train.AMT_INCOME_TOTAL.replace(inc_anomalies.AMT_INCOME_TOTAL.values, np.mean(application_train.AMT_INCOME_TOTAL), inplace = True)\n",
    "\n",
    "# replacing one aberration with mean\n",
    "application_train.OBS_30_CNT_SOCIAL_CIRCLE.replace(max(application_train.OBS_30_CNT_SOCIAL_CIRCLE), np.mean(application_train.OBS_30_CNT_SOCIAL_CIRCLE), inplace = True)\n",
    "application_train.DEF_30_CNT_SOCIAL_CIRCLE.replace(max(application_train.DEF_30_CNT_SOCIAL_CIRCLE), np.mean(application_train.DEF_30_CNT_SOCIAL_CIRCLE), inplace = True)\n",
    "application_train.OBS_60_CNT_SOCIAL_CIRCLE.replace(max(application_train.OBS_60_CNT_SOCIAL_CIRCLE), np.mean(application_train.OBS_60_CNT_SOCIAL_CIRCLE), inplace = True)\n",
    "application_train.DEF_60_CNT_SOCIAL_CIRCLE.replace(max(application_train.DEF_60_CNT_SOCIAL_CIRCLE), np.mean(application_train.DEF_60_CNT_SOCIAL_CIRCLE), inplace = True)\n",
    "\n",
    "application_train1 = application_train.copy()\n",
    "application_test1 = application_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW FEATURES\n",
    "# train\n",
    "application_train['ANN_CRE'] = application_train['AMT_ANNUITY']/application_train['AMT_CREDIT']\n",
    "application_train['DEF_OBS_30'] = application_train['DEF_30_CNT_SOCIAL_CIRCLE']/application_train['OBS_30_CNT_SOCIAL_CIRCLE']\n",
    "application_train['DEF_OBS_60'] = application_train['DEF_60_CNT_SOCIAL_CIRCLE']/application_train['OBS_60_CNT_SOCIAL_CIRCLE']\n",
    "application_train['CRE_INC'] = application_train['AMT_CREDIT']/application_train['AMT_INCOME_TOTAL']\n",
    "application_train['ANN_INC'] = application_train['AMT_ANNUITY']/application_train['AMT_INCOME_TOTAL']\n",
    "\n",
    "application_train['OWN_CAR_AGE_Av'] = -application_train.OWN_CAR_AGE.isnull()\n",
    "application_train['OCCUPATION_TYPE_Av'] = -application_train.OCCUPATION_TYPE.isnull()\n",
    "application_train['ORGANIZATION_TYPE_Av'] = -application_train.ORGANIZATION_TYPE.isnull()\n",
    "application_train['EXT_SOURCE_1_Av'] = -application_train.EXT_SOURCE_1.isnull()\n",
    "application_train['EXT_SOURCE_3_Av'] = -application_train.EXT_SOURCE_3.isnull()\n",
    "application_train['HOUSETYPE_Av'] = -application_train.HOUSETYPE_MODE.isnull()\n",
    "application_train['AMT_REQ_CREDIT_BUREAU_Av'] = -application_train.AMT_REQ_CREDIT_BUREAU_HOUR.isnull()\n",
    "\n",
    "# test\n",
    "application_test['ANN_CRE'] = application_test['AMT_ANNUITY']/application_test['AMT_CREDIT']\n",
    "application_test['DEF_OBS_30'] = application_test['DEF_30_CNT_SOCIAL_CIRCLE']/application_test['OBS_30_CNT_SOCIAL_CIRCLE']\n",
    "application_test['DEF_OBS_60'] = application_test['DEF_60_CNT_SOCIAL_CIRCLE']/application_test['OBS_60_CNT_SOCIAL_CIRCLE']\n",
    "application_test['CRE_INC'] = application_test['AMT_CREDIT']/application_test['AMT_INCOME_TOTAL']\n",
    "application_test['ANN_INC'] = application_test['AMT_ANNUITY']/application_test['AMT_INCOME_TOTAL']\n",
    "\n",
    "application_test['OWN_CAR_AGE_Av'] = -application_test.OWN_CAR_AGE.isnull()\n",
    "application_test['OCCUPATION_TYPE_Av'] = -application_test.OCCUPATION_TYPE.isnull()\n",
    "application_test['ORGANIZATION_TYPE_Av'] = -application_test.ORGANIZATION_TYPE.isnull()\n",
    "application_test['EXT_SOURCE_1_Av'] = -application_test.EXT_SOURCE_1.isnull()\n",
    "application_test['EXT_SOURCE_3_Av'] = -application_test.EXT_SOURCE_3.isnull()\n",
    "application_test['HOUSETYPE_Av'] = -application_test.HOUSETYPE_MODE.isnull()\n",
    "application_test['AMT_REQ_CREDIT_BUREAU_Av'] = -application_test.AMT_REQ_CREDIT_BUREAU_HOUR.isnull()\n",
    "\n",
    "application_train2 = application_train.copy()\n",
    "application_test2 = application_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values imputation as per best strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables having missing values\n",
    "cat_var = application_train.dtypes[application_train.dtypes == 'object'].index\n",
    "\n",
    "# Numerical variables having missing values\n",
    "num_var = application_train.dtypes[application_train.dtypes != 'object'].index[2:]\n",
    "\n",
    "# IMPUTATION of missing values train\n",
    "imp = impute.SimpleImputer(missing_values=np.NaN, strategy= 'constant', fill_value = 'xan')\n",
    "application_train[cat_var] = imp.fit_transform(application_train[cat_var])\n",
    "\n",
    "imp = impute.SimpleImputer(missing_values=np.NaN, strategy= 'median')\n",
    "application_train[num_var] = imp.fit_transform(application_train[num_var])\n",
    "\n",
    "# IMPUTATION of missing values test\n",
    "imp = impute.SimpleImputer(missing_values=np.NaN, strategy= 'constant', fill_value = 'xan')\n",
    "application_test[cat_var] = imp.fit_transform(application_test[cat_var])\n",
    "\n",
    "imp = impute.SimpleImputer(missing_values=np.NaN, strategy= 'median')\n",
    "application_test[num_var] = imp.fit_transform(application_test[num_var])\n",
    "\n",
    "application_train3 = application_train.copy()\n",
    "application_test3 = application_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummification and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMMIFICATION of categorical variables\n",
    "logistic_train = application_train.copy()\n",
    "dummy_train = logistic_train[cat_var]\n",
    "dummy_train['code'] = 1\n",
    "\n",
    "logistic_test = application_test.copy()\n",
    "dummy_test = logistic_test[cat_var]\n",
    "dummy_test['code'] = 0\n",
    "\n",
    "dummy_joined = pd.concat([dummy_train, dummy_test])\n",
    "dummy_joined = pd.get_dummies(dummy_joined, drop_first = True)\n",
    "\n",
    "dummy_train = dummy_joined[dummy_joined.code == 1]\n",
    "logistic_train = logistic_train.drop(cat_var, axis=1)\n",
    "logistic_train = pd.concat([logistic_train, dummy_train], axis = 1)\n",
    "logistic_train = logistic_train.drop('code', axis = 1)\n",
    "\n",
    "dummy_test = dummy_joined[dummy_joined.code == 0]\n",
    "logistic_test = logistic_test.drop(cat_var, axis=1)\n",
    "logistic_test = pd.concat([logistic_test, dummy_test], axis = 1)\n",
    "logistic_test = logistic_test.drop('code', axis = 1)\n",
    "\n",
    "\n",
    "# STANDARDIZATION of variables \n",
    "logistic_train.iloc[:,2:] = logistic_train.iloc[:,2:].apply(lambda x: (x - np.mean(x)) / np.std(x), axis = 0)\n",
    "\n",
    "logistic_test.iloc[:,1:] = logistic_test.iloc[:,1:].apply(lambda x: (x - np.mean(x)) / np.std(x), axis = 0)\n",
    "logistic_test[['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_12',\n",
    "       'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n",
    "       'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_19',\n",
    "       'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'CODE_GENDER_xan',\n",
    "       'NAME_INCOME_TYPE_Maternity leave', 'NAME_FAMILY_STATUS_Unknown']] = 0\n",
    "\n",
    "application_train3 = logistic_train.copy()\n",
    "application_test3 = logistic_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Features in logistic_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding importanr features through sklearn.feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE',\n",
       "       'OWN_CAR_AGE', 'FLAG_WORK_PHONE', 'FLAG_PHONE',\n",
       "       'REGION_RATING_CLIENT_W_CITY', 'REG_CITY_NOT_LIVE_CITY', 'EXT_SOURCE_1',\n",
       "       'EXT_SOURCE_2', 'EXT_SOURCE_3', 'BASEMENTAREA_AVG', 'NONLIVINGAREA_AVG',\n",
       "       'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE',\n",
       "       'FLOORSMAX_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE',\n",
       "       'COMMONAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
       "       'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_8',\n",
       "       'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_16',\n",
       "       'FLAG_DOCUMENT_18', 'AMT_REQ_CREDIT_BUREAU_QRT',\n",
       "       'AMT_REQ_CREDIT_BUREAU_YEAR', 'age_yrs', 'yrs_emp', 'yrs_registration',\n",
       "       'yrs_id_publish', 'yrs_last_phone_change', 'ANN_CRE', 'CRE_INC',\n",
       "       'ANN_INC', 'OWN_CAR_AGE_Av', 'EXT_SOURCE_1_Av',\n",
       "       'AMT_REQ_CREDIT_BUREAU_Av', 'NAME_CONTRACT_TYPE_Revolving loans',\n",
       "       'CODE_GENDER_M', 'FLAG_OWN_CAR_Y', 'NAME_INCOME_TYPE_Student',\n",
       "       'NAME_INCOME_TYPE_Working', 'NAME_EDUCATION_TYPE_Higher education',\n",
       "       'NAME_EDUCATION_TYPE_Lower secondary',\n",
       "       'NAME_EDUCATION_TYPE_Secondary / secondary special',\n",
       "       'NAME_FAMILY_STATUS_Married', 'NAME_HOUSING_TYPE_Municipal apartment',\n",
       "       'OCCUPATION_TYPE_Drivers', 'OCCUPATION_TYPE_Laborers',\n",
       "       'OCCUPATION_TYPE_Low-skill Laborers', 'OCCUPATION_TYPE_Sales staff',\n",
       "       'OCCUPATION_TYPE_Security staff', 'ORGANIZATION_TYPE_Construction',\n",
       "       'ORGANIZATION_TYPE_Industry: type 9', 'ORGANIZATION_TYPE_Military',\n",
       "       'ORGANIZATION_TYPE_Police', 'ORGANIZATION_TYPE_School',\n",
       "       'ORGANIZATION_TYPE_Security Ministries',\n",
       "       'ORGANIZATION_TYPE_Self-employed', 'ORGANIZATION_TYPE_Trade: type 2',\n",
       "       'ORGANIZATION_TYPE_Transport: type 3', 'EMERGENCYSTATE_MODE_xan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = logistic_train.iloc[:, 2:]\n",
    "y_train = logistic_train.TARGET\n",
    "\n",
    "from sklearn import feature_selection\n",
    "logitmodel = linear_model.LogisticRegression(C = .001, class_weight = 'balanced')\n",
    "sfm = feature_selection.SelectFromModel(logitmodel)\n",
    "sfm.fit(X_train, y_train)\n",
    "feature_index = sfm.get_support()\n",
    "imp_features = X_train.columns[feature_index]\n",
    "imp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_train_red = pd.concat([logistic_train[['SK_ID_CURR', 'TARGET']], logistic_train[imp_features]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6851811290954184\n",
      "0.6867243021179343\n"
     ]
    }
   ],
   "source": [
    "# Train-Test Split\n",
    "one_index = logistic_train_red[logistic_train_red.TARGET == 1].index\n",
    "zero_index = logistic_train_red[logistic_train_red.TARGET == 0].index\n",
    "\n",
    "trainindex1 = np.random.choice(one_index, size = int(0.7*one_index.shape[0]), replace = False)\n",
    "trainindex0 = np.random.choice(zero_index, size = int(0.7*zero_index.shape[0]), replace = False)\n",
    "trainindex = np.concatenate([trainindex1, trainindex0])\n",
    "testindex = np.delete(logistic_train_red.index, trainindex)\n",
    "\n",
    "fit_df = logistic_train_red.iloc[trainindex]\n",
    "validation_df = logistic_train_red.iloc[testindex]\n",
    "\n",
    "X_fit = fit_df.drop(['SK_ID_CURR', 'TARGET'], axis = 1)\n",
    "y_fit = fit_df['TARGET']\n",
    "X_validation = validation_df.drop(['SK_ID_CURR', 'TARGET'], axis = 1)\n",
    "y_validation = validation_df['TARGET']\n",
    "\n",
    "# # Model fit and prediction\n",
    "\n",
    "logitmodel = linear_model.LogisticRegression(C = .001, class_weight = 'balanced')\n",
    "logitmodel.fit(X_fit, y_fit)\n",
    "\n",
    "y_pred_fit = logitmodel.predict(X_fit)\n",
    "print(metrics.roc_auc_score(y_fit, y_pred_fit))\n",
    "\n",
    "y_pred_validation = logitmodel.predict(X_validation)\n",
    "print(metrics.roc_auc_score(y_validation, y_pred_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We have reduced from 246 features to 68 features without significant loss in validation roc_auc_score'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'We have reduced from {} features to {} features without significant loss in validation roc_auc_score'.format(logistic_train.shape[1]-2, logistic_train_red.shape[1]-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_test_red = pd.concat([logistic_test[['SK_ID_CURR']], logistic_test[imp_features]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting TARGET in test reduced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = logistic_train_red.iloc[:, 2:]\n",
    "# y_train = logistic_train_red.TARGET\n",
    "# X_test = logistic_test_red.iloc[:, 1:]\n",
    "\n",
    "# # Model fit and prediction\n",
    "# logitmodel = linear_model.LogisticRegression(C = 0.1, class_weight = 'balanced')\n",
    "# logitmodel.fit(X_train, y_train)\n",
    "# y_pred = logitmodel.predict(X_test)\n",
    "# sol_log = pd.DataFrame({'SK_ID_CURR': logistic_test.iloc[:, 0], 'TARGET': y_pred})\n",
    "# sol_log.to_csv('./soln/sol_log2.csv', index = False)                   # kaggle: 0.68594 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_train_red.to_csv('./data/app_train_mod.csv', index=False)\n",
    "# logistic_test_red.to_csv('./data/app_test_mod.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
