{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import impute\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = pd.read_csv('./data/merged_train.csv')\n",
    "merged_test = pd.read_csv('./data/merged_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Validation-Test Split (without PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-validation split\n",
    "X_train, X_validation, y_train, y_validation = model_selection.train_test_split(\n",
    "    merged_train.drop('SK_ID_CURR', axis = 1), merged_train.TARGET,\n",
    "    test_size=0.30, random_state=0, stratify=merged_train.TARGET)\n",
    "\n",
    "# upsample\n",
    "X_train_0 = X_train[X_train.TARGET == 0]\n",
    "X_train_1 = X_train[X_train.TARGET == 1]\n",
    "X_train_1 = X_train_1.sample(X_train_0.shape[0], replace=True)\n",
    "X_train = pd.concat([X_train_0, X_train_1], axis = 0)\n",
    "y_train = X_train.TARGET\n",
    "X_train = X_train.drop('TARGET', axis = 1)\n",
    "\n",
    "X_validation = X_validation.drop('TARGET', axis = 1)\n",
    "\n",
    "\n",
    "# train-test split for KAGGLE entry\n",
    "Xs_train = merged_train.copy()\n",
    "Xs_train_0 = Xs_train[Xs_train.TARGET == 0]\n",
    "Xs_train_1 = Xs_train[Xs_train.TARGET == 1]\n",
    "Xs_train_1 = Xs_train_1.sample(Xs_train_0.shape[0], replace=True)\n",
    "Xs_train = pd.concat([Xs_train_0, Xs_train_1], axis = 0)\n",
    "ys_train = Xs_train.TARGET\n",
    "Xs_train = Xs_train.drop(['SK_ID_CURR', 'TARGET'], axis = 1)\n",
    "\n",
    "Xs_test = merged_test.drop('SK_ID_CURR', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 250    max_depth: 11    max_features: 11\n",
      "train_roc: 0.88    validation_roc: 0.758\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.866184</td>\n",
       "      <td>0.881395</td>\n",
       "      <td>0.001611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.865569</td>\n",
       "      <td>0.880678</td>\n",
       "      <td>0.001613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.865482</td>\n",
       "      <td>0.880594</td>\n",
       "      <td>0.001326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.864678</td>\n",
       "      <td>0.879819</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.837005</td>\n",
       "      <td>0.849773</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.811644</td>\n",
       "      <td>0.821621</td>\n",
       "      <td>0.002192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.791186</td>\n",
       "      <td>0.798470</td>\n",
       "      <td>0.002254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.791097</td>\n",
       "      <td>0.798303</td>\n",
       "      <td>0.001714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.774925</td>\n",
       "      <td>0.779924</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.773490</td>\n",
       "      <td>0.778530</td>\n",
       "      <td>0.002006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.761580</td>\n",
       "      <td>0.764746</td>\n",
       "      <td>0.002969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.751443</td>\n",
       "      <td>0.753686</td>\n",
       "      <td>0.002676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.751016</td>\n",
       "      <td>0.753284</td>\n",
       "      <td>0.002232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.750940</td>\n",
       "      <td>0.753082</td>\n",
       "      <td>0.001141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.750909</td>\n",
       "      <td>0.753160</td>\n",
       "      <td>0.001951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators param_max_depth param_max_features  mean_test_score  \\\n",
       "0                250              11                 11         0.866184   \n",
       "0                300              11                 10         0.865569   \n",
       "1                250              11                 10         0.865482   \n",
       "0                200              11                 10         0.864678   \n",
       "0                200              10                 10         0.837005   \n",
       "1                200               9                 10         0.811644   \n",
       "0                250               8                 10         0.791186   \n",
       "0                200               8                 10         0.791097   \n",
       "0                200               7                 10         0.774925   \n",
       "2                100               7                 10         0.773490   \n",
       "1                100               6                 10         0.761580   \n",
       "0                100               5                  8         0.751443   \n",
       "0                100               5                 10         0.751016   \n",
       "2                100               5                 10         0.750940   \n",
       "1                100               5                  9         0.750909   \n",
       "\n",
       "   mean_train_score  std_test_score  \n",
       "0          0.881395        0.001611  \n",
       "0          0.880678        0.001613  \n",
       "1          0.880594        0.001326  \n",
       "0          0.879819        0.001800  \n",
       "0          0.849773        0.001567  \n",
       "1          0.821621        0.002192  \n",
       "0          0.798470        0.002254  \n",
       "0          0.798303        0.001714  \n",
       "0          0.779924        0.001991  \n",
       "2          0.778530        0.002006  \n",
       "1          0.764746        0.002969  \n",
       "0          0.753686        0.002676  \n",
       "0          0.753284        0.002232  \n",
       "2          0.753082        0.001141  \n",
       "1          0.753160        0.001951  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation\n",
    "rfmodel = ensemble.RandomForestClassifier()\n",
    "param_grid = {'n_estimators': [250], 'max_depth':[11], 'max_features':[11]}\n",
    "gridmodel = model_selection.GridSearchCV(rfmodel, param_grid, scoring = 'roc_auc', cv = 5)\n",
    "gridmodel.fit(X_train, y_train)\n",
    "\n",
    "print('n_estimators:', gridmodel.best_estimator_.n_estimators, '  ',\n",
    "      'max_depth:', gridmodel.best_estimator_.max_depth, '  ',\n",
    "      'max_features:', gridmodel.best_estimator_.max_features)\n",
    "print('train_roc:', round(gridmodel.score(X_train, y_train), 3), '  ',\n",
    "      'validation_roc:', round(gridmodel.score(X_validation, y_validation), 3))\n",
    "\n",
    "\n",
    "rf = pd.DataFrame(gridmodel.cv_results_)[['param_n_estimators', 'param_max_depth', 'param_max_features',\n",
    "                                      'mean_test_score', 'mean_train_score', 'std_test_score']]\n",
    "try:\n",
    "    rf_results = pd.concat([rf_results, rf])\n",
    "except:\n",
    "    rf_results = rf.copy()\n",
    "rf_results.sort_values(by = 'mean_test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation results\n",
    "# n_estimators: 100    max_depth: 5    max_features: 10\n",
    "# train_roc: 0.753    validation_roc: 0.743\n",
    "#-----------------------------------------------------\n",
    "# n_estimators: 100    max_depth: 5    max_features: 8\n",
    "# train_roc: 0.75    validation_roc: 0.739\n",
    "#-----------------------------------------------------\n",
    "# n_estimators: 200    max_depth: 7    max_features: 10\n",
    "# train_roc: 0.779    validation_roc: 0.751\n",
    "#-----------------------------------------------------\n",
    "# n_estimators: 250    max_depth: 8    max_features: 10\n",
    "# train_roc: 0.798    validation_roc: 0.755\n",
    "#------------------------------------------------------\n",
    "# n_estimators: 250    max_depth: 11    max_features: 10\n",
    "# train_roc: 0.879    validation_roc: 0.758\n",
    "#------------------------------------------------------\n",
    "# n_estimators: 300    max_depth: 11    max_features: 10\n",
    "# train_roc: 0.879    validation_roc: 0.758\n",
    "#------------------------------------------------------\n",
    "# n_estimators: 250    max_depth: 11    max_features: 11\n",
    "# train_roc: 0.88    validation_roc: 0.758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle prediction\n",
    "model = ensemble.RandomForestClassifier(n_estimators = 250, max_depth = 11, max_features = 11)\n",
    "model.fit(Xs_train, ys_train)\n",
    "y_pred = model.predict_proba(Xs_test)\n",
    "\n",
    "sol = pd.DataFrame({'SK_ID_CURR': merged_test.SK_ID_CURR, 'TARGET': y_pred[:,1]})\n",
    "sol.to_csv('./soln/sol_mergedrf.csv', index = False)       # kaggle: 0.74832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Components + Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train = merged_train.drop(['SK_ID_CURR', 'TARGET'], axis = 1)\n",
    "pca_test = merged_test.drop('SK_ID_CURR', axis = 1)\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09629084, 0.1434437 , 0.18086675, 0.21595072, 0.24429443,\n",
       "       0.26771517, 0.29046498, 0.3114567 , 0.33148482, 0.34891427,\n",
       "       0.36538338, 0.38127357, 0.39701726, 0.41227906, 0.42687093,\n",
       "       0.44129709, 0.45515265, 0.46824045, 0.48062982, 0.4924454 ,\n",
       "       0.50371793, 0.5148239 , 0.52546174, 0.53608312, 0.54641224,\n",
       "       0.55661707, 0.56674783, 0.57663001, 0.58638171, 0.59607871,\n",
       "       0.60555381, 0.61498931, 0.62441449, 0.63379657, 0.64315874,\n",
       "       0.65249762, 0.66175729, 0.67098652, 0.6801726 , 0.6892577 ,\n",
       "       0.69825182, 0.70711182, 0.71592715, 0.72467476, 0.73336655,\n",
       "       0.74198072, 0.7505091 , 0.75898807, 0.76742898, 0.77562808,\n",
       "       0.7838143 , 0.79191561, 0.79992325, 0.80783446, 0.81559754,\n",
       "       0.82321767, 0.8308116 , 0.83824203, 0.8455526 , 0.85271439,\n",
       "       0.85958735, 0.86631893, 0.87295211, 0.87948419, 0.88583125,\n",
       "       0.89185639, 0.89769615, 0.90334177, 0.90893179, 0.91427557,\n",
       "       0.9194328 , 0.92444586, 0.92941033, 0.93433102, 0.93923843,\n",
       "       0.94330169, 0.94695013, 0.95046868, 0.95390195, 0.95731483,\n",
       "       0.96052653, 0.96321444, 0.96578817, 0.96823222, 0.9705948 ,\n",
       "       0.97288135, 0.97511003, 0.97725016, 0.97936117, 0.98144801,\n",
       "       0.98338515, 0.98504833, 0.98656877, 0.98799326, 0.98936853,\n",
       "       0.9904419 , 0.99143904, 0.99234072, 0.99315463, 0.99388232,\n",
       "       0.99453613, 0.99515544, 0.99577086, 0.99637423, 0.99687856,\n",
       "       0.9973329 , 0.99767323, 0.99797809, 0.99825607, 0.9985247 ,\n",
       "       0.99872879, 0.99891112, 0.99906591, 0.99921677, 0.99935347,\n",
       "       0.99948934, 0.99962117, 0.99974747, 0.99984457, 0.99990443,\n",
       "       0.99993089, 0.99995544, 0.99997477, 0.99999265, 0.99999799,\n",
       "       0.99999961, 0.99999994, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping last 40 which explain less than 1% variance\n",
    "pca = decomposition.PCA(n_components = 95)\n",
    "pca.fit(pca_train)\n",
    "pca_train = pca.transform(pca_train)\n",
    "pca_test = pca.transform(pca_test)\n",
    "pca_train1 = pca_train.copy()\n",
    "pca_test1 = pca_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train = pd.concat([merged_train[['SK_ID_CURR', 'TARGET']], pd.DataFrame(pca_train)], axis = 1)\n",
    "pca_test = pd.concat([merged_test[['SK_ID_CURR']], pd.DataFrame(pca_test)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-validation split for logistic after pca\n",
    "X_train, X_validation, y_train, y_validation = model_selection.train_test_split(\n",
    "    pca_train.drop('SK_ID_CURR', axis = 1), pca_train.TARGET,\n",
    "    test_size=0.30, random_state=0, stratify=pca_train.TARGET)\n",
    "\n",
    "# upsample\n",
    "X_train_0 = X_train[X_train.TARGET == 0]\n",
    "X_train_1 = X_train[X_train.TARGET == 1]\n",
    "X_train_1 = X_train_1.sample(X_train_0.shape[0], replace=True)\n",
    "X_train = pd.concat([X_train_0, X_train_1], axis = 0)\n",
    "y_train = X_train.TARGET\n",
    "X_train = X_train.drop('TARGET', axis = 1)\n",
    "\n",
    "X_validation = X_validation.drop('TARGET', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split for kaggle entry with logistics after pca\n",
    "Xs_train = pca_train.copy()\n",
    "Xs_train_0 = Xs_train[Xs_train.TARGET == 0]\n",
    "Xs_train_1 = Xs_train[Xs_train.TARGET == 1]\n",
    "Xs_train_1 = Xs_train_1.sample(Xs_train_0.shape[0], replace=True)\n",
    "Xs_train = pd.concat([Xs_train_0, Xs_train_1], axis = 0)\n",
    "ys_train = Xs_train.TARGET\n",
    "Xs_train = Xs_train.drop(['SK_ID_CURR', 'TARGET'], axis = 1)\n",
    "\n",
    "Xs_test = pca_test.drop('SK_ID_CURR', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000.0    train_roc: 0.763    validation_roc: 0.759\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1e+08</td>\n",
       "      <td>0.762813</td>\n",
       "      <td>0.763090</td>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e+07</td>\n",
       "      <td>0.762813</td>\n",
       "      <td>0.763090</td>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.762767</td>\n",
       "      <td>0.763112</td>\n",
       "      <td>0.001639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.762767</td>\n",
       "      <td>0.763112</td>\n",
       "      <td>0.001639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e+06</td>\n",
       "      <td>0.762767</td>\n",
       "      <td>0.763112</td>\n",
       "      <td>0.001639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.762767</td>\n",
       "      <td>0.763112</td>\n",
       "      <td>0.001639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.755224</td>\n",
       "      <td>0.001757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C  mean_test_score  mean_train_score  std_test_score\n",
       "1   1e+08         0.762813          0.763090        0.001681\n",
       "0   1e+07         0.762813          0.763090        0.001681\n",
       "1     100         0.762767          0.763112        0.001639\n",
       "2   10000         0.762767          0.763112        0.001639\n",
       "0   1e+06         0.762767          0.763112        0.001639\n",
       "0     0.1         0.762767          0.763112        0.001639\n",
       "0   1e-05         0.755000          0.755224        0.001757"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation\n",
    "logitmodel = linear_model.LogisticRegression()\n",
    "param_grid = {'C': [1e7, 1e8]}\n",
    "gridmodel = model_selection.GridSearchCV(logitmodel, param_grid, scoring = 'roc_auc', cv = 10)\n",
    "gridmodel.fit(X_train, y_train)\n",
    "\n",
    "print(gridmodel.best_estimator_.C, '  ', 'train_roc:', round(gridmodel.score(X_train, y_train), 3), '  ',\n",
    "      'validation_roc:', round(gridmodel.score(X_validation, y_validation), 3))\n",
    "\n",
    "\n",
    "pclog = pd.DataFrame(gridmodel.cv_results_)[['param_C', 'mean_test_score', 'mean_train_score', 'std_test_score']]\n",
    "try:\n",
    "    pclog_results = pd.concat([pclog_results, pclog])\n",
    "except:\n",
    "    pclog_results = pclog.copy()\n",
    "pclog_results.sort_values(by = 'mean_test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance on validation set\n",
    "# 1e-05    train_roc: 0.756    validation_roc: 0.754\n",
    "# 1000000.0    train_roc: 0.763    validation_roc: 0.759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle prediction\n",
    "model = linear_model.LogisticRegression(C = 100000000)\n",
    "model.fit(Xs_train, ys_train)\n",
    "y_pred = model.predict_proba(Xs_test)\n",
    "\n",
    "sol = pd.DataFrame({'SK_ID_CURR': merged_test.SK_ID_CURR, 'TARGET': y_pred[:,1]})\n",
    "sol.to_csv('./soln/sol_mergedpclog.csv', index = False)       # kaggle: 0.75518"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA + Logistic Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train = merged_train.drop(['SK_ID_CURR', 'TARGET'], axis = 1)\n",
    "pca_test = merged_test.drop('SK_ID_CURR', axis = 1)\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(pca_train)\n",
    "\n",
    "pca_train = pca.transform(pca_train)\n",
    "pca_test = pca.transform(pca_test)\n",
    "pca_train1 = pca_train.copy()\n",
    "pca_test1 = pca_test.copy()\n",
    "\n",
    "pca_train = pd.concat([merged_train[['SK_ID_CURR', 'TARGET']], pd.DataFrame(pca_train)], axis = 1)\n",
    "pca_test = pd.concat([merged_test[['SK_ID_CURR']], pd.DataFrame(pca_test)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-validation split and upsample for logistics after pca\n",
    "X_train, X_validation, y_train, y_validation = model_selection.train_test_split(\n",
    "    pca_train.drop('SK_ID_CURR', axis = 1), pca_train.TARGET,\n",
    "    test_size=0.30, random_state=0, stratify=pca_train.TARGET)\n",
    "\n",
    "X_train_0 = X_train[X_train.TARGET == 0]\n",
    "X_train_1 = X_train[X_train.TARGET == 1]\n",
    "X_train_1 = X_train_1.sample(X_train_0.shape[0], replace=True)     # upsample\n",
    "X_train = pd.concat([X_train_0, X_train_1], axis = 0)\n",
    "y_train = X_train.TARGET\n",
    "X_train = X_train.drop('TARGET', axis = 1)\n",
    "\n",
    "X_validation = X_validation.drop('TARGET', axis = 1)\n",
    "\n",
    "\n",
    "# train-test split and upsample for kaggle entry with logistics after pca\n",
    "Xs_train = pca_train.copy()\n",
    "Xs_train_0 = Xs_train[Xs_train.TARGET == 0]\n",
    "Xs_train_1 = Xs_train[Xs_train.TARGET == 1]\n",
    "Xs_train_1 = Xs_train_1.sample(Xs_train_0.shape[0], replace=True)\n",
    "Xs_train = pd.concat([Xs_train_0, Xs_train_1], axis = 0)\n",
    "ys_train = Xs_train.TARGET\n",
    "Xs_train = Xs_train.drop(['SK_ID_CURR', 'TARGET'], axis = 1)\n",
    "\n",
    "Xs_test = pca_test.drop('SK_ID_CURR', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    train_roc: 0.77    validation_roc: 0.767\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.769309</td>\n",
       "      <td>0.769775</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.769308</td>\n",
       "      <td>0.769774</td>\n",
       "      <td>0.000750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.769308</td>\n",
       "      <td>0.769775</td>\n",
       "      <td>0.000750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C  mean_test_score  mean_train_score  std_test_score\n",
       "0    1000         0.769309          0.769775        0.000751\n",
       "0     100         0.769308          0.769774        0.000750\n",
       "1   10000         0.769308          0.769775        0.000750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation\n",
    "logitmodel = linear_model.LogisticRegression()\n",
    "param_grid = {'C': [100, 10000]}\n",
    "gridmodel = model_selection.GridSearchCV(logitmodel, param_grid, scoring = 'roc_auc', cv = 3)\n",
    "gridmodel.fit(X_train, y_train)\n",
    "\n",
    "print(gridmodel.best_estimator_.C, '  ', 'train_roc:', round(gridmodel.score(X_train, y_train), 3), '  ',\n",
    "      'validation_roc:', round(gridmodel.score(X_validation, y_validation), 3))\n",
    "\n",
    "\n",
    "pclogfull = pd.DataFrame(gridmodel.cv_results_)[['param_C', 'mean_test_score', 'mean_train_score', 'std_test_score']]\n",
    "try:\n",
    "    pclogfull_results = pd.concat([pclogfull_results, pclogfull])\n",
    "except:\n",
    "    pclogfull_results = pclogfull.copy()\n",
    "pclogfull_results.sort_values(by = 'mean_test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000    train_roc: 0.77    validation_roc: 0.767\n",
    "# 100    train_roc: 0.77    validation_roc: 0.767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle prediction\n",
    "model = linear_model.LogisticRegression(C = 10000)\n",
    "model.fit(Xs_train, ys_train)\n",
    "y_pred = model.predict_proba(Xs_test)\n",
    "\n",
    "sol = pd.DataFrame({'SK_ID_CURR': merged_test.SK_ID_CURR, 'TARGET': y_pred[:,1]})\n",
    "sol.to_csv('./soln/sol_merged_pclog_full.csv', index = False)       # kaggle: 0.76641"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
